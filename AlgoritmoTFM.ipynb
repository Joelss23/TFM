{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyP/bvQKkA4evZ3b44FOUB5L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Joelss23/TFM/blob/main/AlgoritmoTFM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MODELO DE APRENDIZAJE AUTOMÁTICO PARA LA GESTIÓN DE CALIDAD Y PRODUCCION VINICOLA: IMPLEMENTACIÓN DE UN SISTEMA DE CALIDAD BASADO EN DATOS"
      ],
      "metadata": {
        "id": "jdqGhmAILPtK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Resumen"
      ],
      "metadata": {
        "id": "5W9ozqDdMOnE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "G9HL7bBqMTPc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## #1. Instalación y Carga de Librerías"
      ],
      "metadata": {
        "id": "uSa8VWAnMT1p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Instalación de Paquetes"
      ],
      "metadata": {
        "id": "C6YwXjGvjvdX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Instalación de paquetes necesarios\n",
        "!pip install --upgrade google-cloud-storage openpyxl scikit-learn imbalanced-learn seaborn\n",
        "!pip install google-cloud-bigquery pandas"
      ],
      "metadata": {
        "id": "1pX2_2qnjtEi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importación de Librerias"
      ],
      "metadata": {
        "id": "38E2fxxQj5sl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importación de librerías básicas\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "#Librerías para Machine Learning y Preprocesamiento\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import roc_auc_score, precision_score, recall_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.tree import plot_tree\n",
        "\n",
        "#Librerías para balanceo\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "#Librerías para Deep Learning\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "#Librerías para Google Cloud\n",
        "from google.colab import files\n",
        "from google.cloud import storage\n",
        "from google.cloud import bigquery\n",
        "from google.auth import default\n",
        "from google.auth.exceptions import DefaultCredentialsError\n",
        "\n",
        "#Librerías del sistema\n",
        "import os"
      ],
      "metadata": {
        "id": "81Xybnc7SxZD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## #2. Autenticación, Carga y Descarga de Datos Desde Google Cloud Storage (GCS)"
      ],
      "metadata": {
        "id": "jkA2Gp8zNELx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Validación de Clave de Acceso"
      ],
      "metadata": {
        "id": "2NO8IMMSsgUi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Subir el archivo de claves JSON para la autenticación\n",
        "print(\"Por favor, sube el archivo de clave JSON para la autenticación:\")\n",
        "uploaded = files.upload()\n",
        "json_key_path = '/content/Clave-acceso-GCS.json'  #Ajustar el nombre de archivo en caso de ser necesario\n",
        "\n",
        "#Establecer la variable de entorno para la autenticación\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = json_key_path\n",
        "\n",
        "#Verificar autenticación e inicializar cliente de GCS\n",
        "try:\n",
        "    storage_client = storage.Client()\n",
        "    print(\"\\nAutenticación exitosa con Google Cloud.\")\n",
        "except DefaultCredentialsError as e:\n",
        "    print(f\"\\nError de autenticación: {e}\")"
      ],
      "metadata": {
        "id": "ltfFPUxcsn2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Carga del Archivo (Datos) al bucket de GCS"
      ],
      "metadata": {
        "id": "j44S5HaVuNbF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Subir archivo desde la máquina local\n",
        "print(\"Por favor, sube el archivo Excel desde la máquina local:\")\n",
        "uploaded = files.upload()\n",
        "local_excel_filename = list(uploaded.keys())[0]\n",
        "\n",
        "#Subir el archivo al bucket\n",
        "bucket_name = 'sistema-calidad-vino-datos'  #Nombre del proyecto en GCS\n",
        "blob_name = 'Dataset_Vinos_TFM.xlsx'        #Nombre que tendrá el archivo en GCS\n",
        "\n",
        "bucket = storage_client.bucket(bucket_name)\n",
        "blob = bucket.blob(blob_name)\n",
        "\n",
        "#Subir a GCS\n",
        "blob.upload_from_filename(local_excel_filename)\n",
        "\n",
        "print(f\"\\nArchivo '{local_excel_filename}' subido exitosamente a gs://{bucket_name}/{blob_name}\")"
      ],
      "metadata": {
        "id": "z7tMqkE7uZzz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Carga de Datos Interna"
      ],
      "metadata": {
        "id": "FbCuSUIGka7t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Guardar el DataFrame localmente como CSV\n",
        "df = pd.read_excel(local_excel_filename)\n",
        "csv_file_name = local_excel_filename.replace('.xlsx', '.csv')\n",
        "df.to_csv(csv_file_name, index=False)\n",
        "\n",
        "#Confirmación de la exportación\n",
        "print(f\"Archivo convertido a CSV y guardado como: {csv_file_name}\")"
      ],
      "metadata": {
        "id": "4GkNQ4w6sPgu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## #3. Carga del Dataset y Validación Inicial"
      ],
      "metadata": {
        "id": "3cfQatPdNdc0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Cargar el dataset\n",
        "#(Si se cambio el nombre del archivo previamente aca debera tener el mismo de arriba)\n",
        "df = pd.read_excel('Dataset_Vinos_TFM.xlsx')\n",
        "\n",
        "#Mostrar los primeros 5 y los últimos 5 registros para validar que se ha cargado correctamente\n",
        "print(\"Primeros 5 registros:\")\n",
        "print(df.head())\n",
        "print(\"\\nÚltimos 5 registros:\")\n",
        "print(df.tail())"
      ],
      "metadata": {
        "id": "9-3AMptxTLZ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## #4. Analisis Exploratorio"
      ],
      "metadata": {
        "id": "h0LJScPuSwfK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Informacion General del Dataset"
      ],
      "metadata": {
        "id": "A6ne9MY4km_0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Mostrar información general sobre las columnas (tipos de datos)\n",
        "print(\"Información del dataset:\")\n",
        "print(df.info())"
      ],
      "metadata": {
        "id": "1W7V09A-TWgk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Estadísticas Básicas del Dataset"
      ],
      "metadata": {
        "id": "jZc1nEvjkr94"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Estadísticas básicas\n",
        "print(\"Estadísticas básicas:\")\n",
        "print(df.describe())"
      ],
      "metadata": {
        "id": "L6UIy2oAi-Yh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Información General de las Columnas del Dataset"
      ],
      "metadata": {
        "id": "T_V1BWC7kzk2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Información general de las columnas\n",
        "print(\"Información del dataset:\")\n",
        "print(df.info())"
      ],
      "metadata": {
        "id": "VDZhNKMbi_lI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Valores Nulos"
      ],
      "metadata": {
        "id": "cbAgMLOzk8lF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Valores nulos\n",
        "print(\"Valores nulos por columna:\")\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "id": "2hnowXMqjAqA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Filas Duplicadas"
      ],
      "metadata": {
        "id": "InR3uy4MlAH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Filas duplicadas\n",
        "print(\"Cantidad de filas duplicadas:\")\n",
        "print(df.duplicated().sum())"
      ],
      "metadata": {
        "id": "DN-Xv9IOjBoq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Distrubición de Variables"
      ],
      "metadata": {
        "id": "uaKz9EBylDbL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Distribución de variables categóricas relevantes\n",
        "print(\"Distribución por Tipo de Vino:\")\n",
        "print(df['Tipo de Vino'].value_counts())\n",
        "print(\"\\nDistribución por Tipo de Uva:\")\n",
        "print(df['Tipo de Uva'].value_counts())"
      ],
      "metadata": {
        "id": "9_tNJlaajCQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## #5. Ingeniería de Variables - Crear Variable de Calidad"
      ],
      "metadata": {
        "id": "PRFwfsgFOt89"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Función para evaluar calidad\n",
        "def evaluar_calidad(row, tipo_vino):\n",
        "    if tipo_vino == \"VINOTINTO\":\n",
        "        return 'Buena' if (12.5 <= row['Grado Alcoholico Adquirido'] <= 14.5 and\n",
        "                           20 <= row['Sulfuroso Libre (mg/L)'] <= 30 and\n",
        "                           row['Sulfuroso Total (mg/L)'] <= 150 and\n",
        "                           4.5 <= row['Acidez Total (g/L)'] <= 6.0 and\n",
        "                           row['Acidez Volatil (g/L)'] <= 0.6 and\n",
        "                           3.3 <= row['pH'] <= 3.6 and\n",
        "                           row['Azucares Reductores (g/L)'] < 4) else 'Mala'\n",
        "    elif tipo_vino == \"VINOBLANCO\":\n",
        "        return 'Buena' if (11.5 <= row['Grado Alcoholico Adquirido'] <= 13.5 and\n",
        "                           25 <= row['Sulfuroso Libre (mg/L)'] <= 40 and\n",
        "                           row['Sulfuroso Total (mg/L)'] <= 180 and\n",
        "                           5.5 <= row['Acidez Total (g/L)'] <= 7.5 and\n",
        "                           row['Acidez Volatil (g/L)'] <= 0.5 and\n",
        "                           3.1 <= row['pH'] <= 3.4 and\n",
        "                           row['Azucares Reductores (g/L)'] < 4) else 'Mala'\n",
        "    elif tipo_vino == \"VINOROSADO\":\n",
        "        return 'Buena' if (11.5 <= row['Grado Alcoholico Adquirido'] <= 13.5 and\n",
        "                           25 <= row['Sulfuroso Libre (mg/L)'] <= 40 and\n",
        "                           row['Sulfuroso Total (mg/L)'] <= 180 and\n",
        "                           5.0 <= row['Acidez Total (g/L)'] <= 7.0 and\n",
        "                           row['Acidez Volatil (g/L)'] <= 0.5 and\n",
        "                           3.1 <= row['pH'] <= 3.5 and\n",
        "                           row['Azucares Reductores (g/L)'] < 4) else 'Mala'\n",
        "    return 'Desconocido'\n",
        "\n",
        "#Aplicar función\n",
        "df['Conformidad'] = df.apply(lambda row: evaluar_calidad(row, row['Tipo de Vino']), axis=1)\n",
        "\n",
        "#Visualizar nuevas etiquetas\n",
        "print(\"\\nDistribución de la variable 'Conformidad':\")\n",
        "print(df['Conformidad'].value_counts())"
      ],
      "metadata": {
        "id": "QRjeG6xvTY8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## #6. Limpieza de Datos"
      ],
      "metadata": {
        "id": "08EBugs-O-aj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Limpieza y Preparación de Datos"
      ],
      "metadata": {
        "id": "u0LN6O95mbz0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Eliminar columnas no numéricas innecesarias\n",
        "df_cleaned = df.drop(columns=['# Muestra'])\n",
        "\n",
        "#Separar las columnas numéricas (excluir las categóricas)\n",
        "columns_numericas = df_cleaned.select_dtypes(include=[np.number]).columns\n",
        "X = df_cleaned[columns_numericas]  # Sólo las columnas numéricas\n",
        "y = df_cleaned['Conformidad']\n",
        "\n",
        "#Codificar variable objetivo a 0 (Mala) y 1 (Buena)\n",
        "df_cleaned = df_cleaned[df_cleaned['Conformidad'].isin(['Buena', 'Mala'])]\n",
        "df_cleaned['Conformidad_Bin'] = df_cleaned['Conformidad'].map({'Mala': 0, 'Buena': 1})"
      ],
      "metadata": {
        "id": "m_1URREQmgZ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### División de Datos y Normalización"
      ],
      "metadata": {
        "id": "v2nCICj2mjlP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Preparar datos\n",
        "X = df_cleaned.select_dtypes(include=[np.number]).drop(columns=['Conformidad_Bin'])\n",
        "y = df_cleaned['Conformidad_Bin']\n",
        "\n",
        "#Dividir el dataset en conjunto de entrenamiento y conjunto de prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "#Normalizar solo las columnas numéricas\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train[columns_numericas])\n",
        "\n",
        "#Normalizar conjunto de prueba (utilizando el mismo escalador que se entrenó con X_train)\n",
        "X_test_scaled = scaler.transform(X_test[columns_numericas])"
      ],
      "metadata": {
        "id": "xoT-SUStmlaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conversión a DataFrame y Verificación"
      ],
      "metadata": {
        "id": "pLnhsf66mpEq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Convertir los datos escalados nuevamente a DataFrame para facilitar su manejo\n",
        "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=columns_numericas)\n",
        "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=columns_numericas)\n",
        "\n",
        "#Verificar la forma de los datos escalados\n",
        "print(X_train_scaled_df.head())\n",
        "print(X_test_scaled_df.head())"
      ],
      "metadata": {
        "id": "g9HGgnseTqe7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "FErDIh_ZmFC8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## #7.  Análisis Separado por Tipo de Vino y Tipo de Uva"
      ],
      "metadata": {
        "id": "2fotDfURPKI5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### #7.1 Análisis por Tipo de Vino"
      ],
      "metadata": {
        "id": "P_4wZqu7myk9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Dividir el dataset en subconjuntos por tipo de vino\n",
        "vinotinto = df_cleaned[df_cleaned['Tipo de Vino'] == 'VINOTINTO']\n",
        "vinoblanco = df_cleaned[df_cleaned['Tipo de Vino'] == 'VINOBLANCO']\n",
        "vinorosado = df_cleaned[df_cleaned['Tipo de Vino'] == 'VINOROSADO']"
      ],
      "metadata": {
        "id": "D1jjrCp3nrkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Vinotinto"
      ],
      "metadata": {
        "id": "WM1OJqHRm8Mw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Análisis para Vino Tinto:\")\n",
        "print(vinotinto.describe())"
      ],
      "metadata": {
        "id": "Dn7ja6Z-UAph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Vino Blanco"
      ],
      "metadata": {
        "id": "374DGBp2m_vV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Análisis para Vino Blanco:\")\n",
        "print(vinoblanco.describe())"
      ],
      "metadata": {
        "id": "QUSdc7VHnEN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Vino Rosado"
      ],
      "metadata": {
        "id": "P1Fdk-_jnNbI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Análisis para Vino Rosado:\")\n",
        "print(vinorosado.describe())"
      ],
      "metadata": {
        "id": "TaocH2tKnPrA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### #7.2 Analisis por Tipo de Uva (Vinotinto)"
      ],
      "metadata": {
        "id": "Yy4kj9jSnV4e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Dividir el dataset en subconjuntos por tipo de uva\n",
        "syrah = df_cleaned[df_cleaned['Tipo de Uva'] == 'SYRAH']\n",
        "graciano = df_cleaned[df_cleaned['Tipo de Uva'] == 'GRACIANO']\n",
        "cabernet_sauvignon = df_cleaned[df_cleaned['Tipo de Uva'] == 'CABERNET SAUVIGNON']\n",
        "sauvignon_blanco = df_cleaned[df_cleaned['Tipo de Uva'] == 'SAUVIGNON BLANCO']\n",
        "rosado = df_cleaned[df_cleaned['Tipo de Uva'] == 'ROSADO']"
      ],
      "metadata": {
        "id": "8WmkAi4-UbXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Syrah"
      ],
      "metadata": {
        "id": "z2D9k--Mn6za"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Análisis para uva Syrah:\")\n",
        "print(syrah.describe())"
      ],
      "metadata": {
        "id": "PqL6LAAzn0r7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Graciano"
      ],
      "metadata": {
        "id": "chOOeUXin84u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Análisis para uva Graciano:\")\n",
        "print(graciano.describe())"
      ],
      "metadata": {
        "id": "5PYhPAwSn20v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Cabernet Sauvignon"
      ],
      "metadata": {
        "id": "uUqE16Ehn-WO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Análisis para uva Cabernet Sauvignon:\")\n",
        "print(cabernet_sauvignon.describe())"
      ],
      "metadata": {
        "id": "tPYpmUCSn39l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## #8. Modelado con TensorFlow"
      ],
      "metadata": {
        "id": "g-AKlm9oPaYX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creación del Modelo y Entrenamiento"
      ],
      "metadata": {
        "id": "h4tz3LNgoXlH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Crear el modelo de red neuronal de TensorFlow\n",
        "model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "#Entrenar el modelo\n",
        "model.fit(X_train_scaled, y_train, epochs=10, batch_size=32, validation_data=(X_test_scaled, y_test))"
      ],
      "metadata": {
        "id": "xRChNebrod0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predicciones"
      ],
      "metadata": {
        "id": "zl8KpmTiofc4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Realizar predicciones\n",
        "nn_probs = model.predict(X_test_scaled).flatten()  # predicciones probabilísticas\n",
        "nn_preds = (nn_probs > 0.5).astype(int)  # convertir a clases 0 o 1"
      ],
      "metadata": {
        "id": "Sw_tNGIIokbh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluación del Modelo"
      ],
      "metadata": {
        "id": "AsjLVe0HohnM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluar el desempeño de la red neuronal\n",
        "print(\"Modelo: Red Neuronal\")\n",
        "print(classification_report(y_test, nn_preds))"
      ],
      "metadata": {
        "id": "Qqw_mh2MUqV8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## #9. Análisis y Evaluación del Modelo Predictivo"
      ],
      "metadata": {
        "id": "_EomW6NGQA8J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### #9.1 Analisis de Outliers"
      ],
      "metadata": {
        "id": "mzaimM9AuwwB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Análisis de outliers\n",
        "sns.boxplot(data=X)\n",
        "plt.xticks(rotation=90)\n",
        "plt.title('Distribución de variables - Outliers')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fNtTjtAHu5K7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### #9.2 Balance de clases con SMOTE"
      ],
      "metadata": {
        "id": "KxMyhuuQu6yQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Balance de clases con SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
        "print(\"Distribución de clases después de aplicar SMOTE:\")\n",
        "print(pd.Series(y_resampled).value_counts())"
      ],
      "metadata": {
        "id": "kTETnw9fvA0P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### #9.3 Validación Cruzada"
      ],
      "metadata": {
        "id": "OYK0KTNLvEXv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Validación cruzada\n",
        "cross_val_scores = cross_val_score(RandomForestClassifier(), X_resampled, y_resampled, cv=5)\n",
        "print(f\"Puntuaciones de validación cruzada: {cross_val_scores}\")\n",
        "print(f\"Precisión media de validación cruzada: {cross_val_scores.mean():.4f}\")"
      ],
      "metadata": {
        "id": "w9Fdk76VXXBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## #10. Comparación de Modelos"
      ],
      "metadata": {
        "id": "43JrGB39P5xc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### #10.1 Random Forest"
      ],
      "metadata": {
        "id": "MLsrUeInqfMe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Diccionario para almacenar las precisiones de cada modelo\n",
        "model_accuracies = {}\n",
        "\n",
        "#Entrenar y evaluar el modelo Random Forest\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "rf_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "#Realizar predicciones\n",
        "rf_preds = rf_model.predict(X_test_scaled)\n",
        "\n",
        "#Almacenar precisión\n",
        "model_accuracies[\"Random Forest\"] = accuracy_score(y_test, rf_preds)\n",
        "\n",
        "#Visualización del Random Forest\n",
        "estimator = rf_model.estimators_[0]\n",
        "plt.figure(figsize=(30, 10))\n",
        "plot_tree(estimator, filled=True, feature_names=X_train.columns, class_names=['Mala', 'Buena'], max_depth=3)\n",
        "plt.title(\"Visualización del Random Forest\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "u7NrcWw4qi9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### #10.2 Regresión Logística"
      ],
      "metadata": {
        "id": "YjdcKESMqvA-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Entrenar y evaluar el modelo de Regresión Logística\n",
        "lr_model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "lr_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "#Realizar predicciones\n",
        "lr_preds = lr_model.predict(X_test_scaled)\n",
        "\n",
        "#Almacenar precisión\n",
        "model_accuracies[\"Regresion Logistica\"] = accuracy_score(y_test, lr_preds)\n",
        "\n",
        "#Obtener coeficientes de la regresión logística\n",
        "coeficientes = lr_model.coef_[0]\n",
        "variables = X_train.columns\n",
        "\n",
        "#Crear un nuevo DataFrame con los coeficientes\n",
        "coef_df = pd.DataFrame({'Variable': variables, 'Coeficiente': coeficientes})\n",
        "coef_df = coef_df.sort_values(by='Coeficiente')\n",
        "\n",
        "#Visualización de la importancia de las variables\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='Coeficiente', y='Variable', data=coef_df, palette=\"coolwarm\")\n",
        "plt.title(\"Importancia de las Variables - Regresión Logística\")\n",
        "plt.axvline(0, color='black', linestyle='--')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0C37xuIRquaN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### #10.3 Comparación de Modelos"
      ],
      "metadata": {
        "id": "DqWV3fx6q-NK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Entrenamiento y Evaluación de Modelos"
      ],
      "metadata": {
        "id": "8Jfje5R9rZJ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Comparar Red Neuronal, Random Forest y Regresión Logística\n",
        "models = {\n",
        "    \"Red Neuronal\": model,\n",
        "    \"Random Forest\": rf_model,\n",
        "    \"Regresion Logistica\": lr_model\n",
        "}\n",
        "\n",
        "#Entrenar y evaluar cada modelo\n",
        "for name, model_comp in models.items():\n",
        "    print(f\"\\nModelo: {name}\")\n",
        "    if name == \"Red Neuronal\":\n",
        "        #Entrenamiento específico para la red neuronal\n",
        "        model_comp.fit(X_train_scaled, y_train, epochs=10, batch_size=32, validation_data=(X_test_scaled, y_test), verbose=0)\n",
        "\n",
        "        #Realizar predicciones con la red neuronal\n",
        "        nn_probs = model_comp.predict(X_test_scaled).flatten()  # predicciones probabilísticas\n",
        "        nn_preds = (nn_probs > 0.5).astype(int)  # convertir a clases 0 o 1\n",
        "\n",
        "        #Almacenar la precisión del modelo\n",
        "        model_accuracies[name] = accuracy_score(y_test, nn_preds)\n",
        "\n",
        "        print(\"Red Neuronal\")\n",
        "        print(classification_report(y_test, nn_preds))\n",
        "\n",
        "    else:\n",
        "        #Entrenamiento y predicción para Random Forest y Regresión Logística\n",
        "        model_comp.fit(X_train_scaled, y_train)\n",
        "        preds = model_comp.predict(X_test_scaled)\n",
        "\n",
        "        #Calcular y mostrar el reporte de clasificación\n",
        "        report = classification_report(y_test, preds, digits=2)\n",
        "        print(report)\n",
        "\n",
        "        #Almacenar la precisión del modelo\n",
        "        model_accuracies[name] = accuracy_score(y_test, preds)"
      ],
      "metadata": {
        "id": "hLT_a6burlTm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Comparación de Precisión"
      ],
      "metadata": {
        "id": "bydY2VsFrtaQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Ordenar las precisiones de menor a mayor\n",
        "sorted_accuracies = dict(sorted(model_accuracies.items(), key=lambda item: item[1]))\n",
        "\n",
        "#Crear gráfico de barras para comparar precisiones\n",
        "plt.figure(figsize=(8, 6))\n",
        "bars = plt.bar(sorted_accuracies.keys(), sorted_accuracies.values(), color=['salmon', 'skyblue', 'lightgreen'])\n",
        "\n",
        "#Agregar título y etiquetas\n",
        "plt.title('Comparación de Precisión de Modelos', fontsize=16)\n",
        "plt.xlabel('Modelos', fontsize=12)\n",
        "plt.ylabel('Precisión', fontsize=12)\n",
        "\n",
        "#Agregar las precisiones exactas sobre las barras\n",
        "for bar, accuracy in zip(bars, sorted_accuracies.values()):\n",
        "    yval = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width() / 2, yval + 0, f'{accuracy:.2f}', ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
        "\n",
        "#Mostrar el gráfico\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "byeXvLcerxwq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Comparación de F1-Score"
      ],
      "metadata": {
        "id": "3RvXTnLnsCwO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Calcular y comparar F1-Score de los modelos\n",
        "f1_scores = {}\n",
        "\n",
        "#Evaluar F1-Score para cada modelo\n",
        "for name, model_comp in models.items():\n",
        "    model_comp.fit(X_train_scaled, y_train)\n",
        "\n",
        "    #Obtener las predicciones del modelo\n",
        "    preds_probs = model_comp.predict_proba(X_test_scaled) if hasattr(model_comp, 'predict_proba') else model_comp.predict(X_test_scaled)\n",
        "\n",
        "    #Convertir probabilidades a predicciones binarias (0 o 1)\n",
        "    if preds_probs.ndim > 1 and preds_probs.shape[1] > 1:\n",
        "        preds = (preds_probs[:, 1] > 0.5).astype(int)\n",
        "    else:\n",
        "        preds = preds_probs.astype(int)\n",
        "\n",
        "    f1 = f1_score(y_test, preds)\n",
        "    f1_scores[name] = f1\n",
        "\n",
        "#Agregar el modelo de Red Neuronal\n",
        "nn_preds = model.predict(X_test_scaled)\n",
        "nn_preds = (nn_preds > 0.5).astype(int)\n",
        "f1_nn = f1_score(y_test, nn_preds)\n",
        "f1_scores[\"Red Neuronal\"] = f1_nn\n",
        "\n",
        "#Ordenar los F1-Scores de menor a mayor\n",
        "sorted_f1_scores = dict(sorted(f1_scores.items(), key=lambda item: item[1]))\n",
        "\n",
        "#Gráfico de comparación de F1-Score\n",
        "plt.figure(figsize=(8, 6))\n",
        "bars = plt.bar(sorted_f1_scores.keys(), sorted_f1_scores.values(), color=['salmon', 'skyblue', 'lightgreen'])\n",
        "plt.ylabel('F1-Score')\n",
        "plt.title('Comparación de Modelos - F1 Score')\n",
        "plt.ylim(0, 1)\n",
        "for i, (bar, v) in enumerate(zip(bars, sorted_f1_scores.values())):\n",
        "    plt.text(bar.get_x() + bar.get_width() / 2, v - 0.05, f\"{v:.3f}\", ha='center', fontweight='bold')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ssy0-KuZsFf0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Encontrar el modelo con mejor F1-Score\n",
        "mejor_modelo = max(f1_scores, key=f1_scores.get)\n",
        "mejor_score = f1_scores[mejor_modelo]\n",
        "\n",
        "#Generar el resumen interpretativo\n",
        "print(f\"El modelo con mejor desempeño fue **{mejor_modelo}**, obteniendo un F1-Score de {mejor_score:.3f}.\")\n",
        "print(f\"Este modelo supera en rendimiento a los demás, basándose en un balance óptimo entre precisión y recall.\")"
      ],
      "metadata": {
        "id": "iUnNGVLNq98Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## #11. Guardado de los Resultados con las Predicciones y Exportacion a GSC"
      ],
      "metadata": {
        "id": "s2xSRyL7PtVO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Google Cloud Storage"
      ],
      "metadata": {
        "id": "Ht_oW7vG2FTw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Guardar el dataset completo con predicciones\n",
        "df_cleaned.to_csv('/content/dataset_con_predicciones.csv', index=False)\n",
        "files.download('/content/dataset_con_predicciones.csv')\n",
        "\n",
        "#Subir a Google Cloud Storage\n",
        "blob = bucket.blob('dataset_con_predicciones.csv')\n",
        "blob.upload_from_filename('/content/dataset_con_predicciones.csv')\n",
        "print(\"Archivo 'dataset_con_predicciones.csv' subido a Google Cloud Storage.\")\n",
        "\n",
        "#Filtrar por tipo de vino y guardar archivos individuales\n",
        "tipos_vino = df_cleaned['Tipo de Vino'].unique()\n",
        "\n",
        "for tipo in tipos_vino:\n",
        "    df_vino = df_cleaned[df_cleaned['Tipo de Vino'] == tipo]\n",
        "    nombre_archivo = f'dataset_{tipo.lower()}.csv'\n",
        "    ruta_local = f'/content/{nombre_archivo}'\n",
        "\n",
        "    #Guardar CSV local\n",
        "    df_vino.to_csv(ruta_local, index=False)\n",
        "\n",
        "    #Descargar localmente en Colab\n",
        "    files.download(ruta_local)\n",
        "\n",
        "    #Subir a GCS\n",
        "    blob = bucket.blob(nombre_archivo)\n",
        "    blob.upload_from_filename(ruta_local)\n",
        "    print(f\"Archivo '{nombre_archivo}' subido a Google Cloud Storage.\")"
      ],
      "metadata": {
        "id": "qXXw8FGjVln9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Carga de Datos a Big Query"
      ],
      "metadata": {
        "id": "NcJzM8sauom-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Validacion de Columnas"
      ],
      "metadata": {
        "id": "WvlDNRy6viTC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Renombrar las columnas para que cumplan con los requisitos de BigQuery\n",
        "df_cleaned.columns = df_cleaned.columns.str.replace(' ', '_')  # Reemplaza espacios por guiones bajos\n",
        "df_cleaned.columns = df_cleaned.columns.str.replace('/', '')  # Elimina slash\n",
        "df_cleaned.columns = df_cleaned.columns.str.replace(')', '')  # Elimina paréntesis\n",
        "df_cleaned.columns = df_cleaned.columns.str.replace('(', '')  # Elimina paréntesis\n",
        "\n",
        "#Verificar los nuevos nombres de las columnas\n",
        "print(\"Nombres de columnas después del renombrado:\")\n",
        "print(df_cleaned.columns)\n",
        "\n",
        "#Crear la columna binaria\n",
        "if 'Conformidad_Bin' not in df_cleaned.columns:\n",
        "    df_cleaned['Conformidad_Bin'] = (df_cleaned['Conformidad'] == 'Sí').astype(int)\n",
        "\n",
        "#Convertir 'Registro_muestra' a tipo datetime y luego a date\n",
        "df_cleaned['Registro_muestra'] = pd.to_datetime(df_cleaned['Registro_muestra'], errors='coerce')\n",
        "df_cleaned['Registro_muestra'] = df_cleaned['Registro_muestra'].dt.date\n",
        "\n",
        "#Verificar los tipos de datos después de la conversión\n",
        "print(\"\\nDatos a importar en Google BigQuery:\")\n",
        "print(df_cleaned.dtypes)"
      ],
      "metadata": {
        "id": "JvCQDxYOUdxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Autenticación y Definición de la Tabla en BigQuery"
      ],
      "metadata": {
        "id": "tKaSN8xEvwxh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Establecer la variable de entorno para la autenticación\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = json_key_path\n",
        "\n",
        "#Crear cliente de BigQuery\n",
        "client = bigquery.Client()\n",
        "creds, project = default()\n",
        "print(\"Autenticación exitosa con Google Cloud.\")\n",
        "\n",
        "# Definir proyecto, dataset y tabla en BigQuery\n",
        "project_id = 'sistema-de-calidad-vinos' #Usar el ID del proyecto correcto\n",
        "dataset_id = 'Dataset_Vinos_TFM' #Usar ID del connjunto de datos\n",
        "table_name = 'Tabla_Vinos_Analisis'  #Nombre de la tabla en BigQuery (Editable)\n",
        "table_id = f\"{project_id}.{dataset_id}.{table_name}\"\n",
        "\n",
        "#Crear el dataset\n",
        "datasets = list(client.list_datasets(project=project_id))\n",
        "dataset_names = [d.dataset_id for d in datasets]\n",
        "\n",
        "if dataset_id not in dataset_names:\n",
        "    dataset_ref = bigquery.Dataset(f\"{project_id}.{dataset_id}\")\n",
        "    dataset_ref.location = \"EU\"  # Puedes cambiar la región si lo necesitas\n",
        "    client.create_dataset(dataset_ref)\n",
        "    print(f\"Dataset '{dataset_id}' creado en el proyecto '{project_id}'.\")\n",
        "\n",
        "#Definir el esquema para BigQuery basado en las columnas del DataFrame\n",
        "job_config = bigquery.LoadJobConfig(\n",
        "    schema=[\n",
        "        bigquery.SchemaField(\"Tipo_de_Vino\", \"STRING\"),\n",
        "        bigquery.SchemaField(\"Tipo_de_Uva\", \"STRING\"),\n",
        "        bigquery.SchemaField(\"Registro_muestra\", \"DATE\"),\n",
        "        bigquery.SchemaField(\"Deposito\", \"STRING\"),\n",
        "        bigquery.SchemaField(\"Litros\", \"FLOAT\"),\n",
        "        bigquery.SchemaField(\"Grado_Alcoholico_Adquirido\", \"FLOAT\"),\n",
        "        bigquery.SchemaField(\"Sulfuroso_Libre_mgL\", \"FLOAT\"),\n",
        "        bigquery.SchemaField(\"Sulfuroso_Total_mgL\", \"FLOAT\"),\n",
        "        bigquery.SchemaField(\"Acidez_Total_gL\", \"FLOAT\"),\n",
        "        bigquery.SchemaField(\"Acidez_Volatil_gL\", \"FLOAT\"),\n",
        "        bigquery.SchemaField(\"pH\", \"FLOAT\"),\n",
        "        bigquery.SchemaField(\"Azucares_Reductores_gL\", \"FLOAT\"),\n",
        "        bigquery.SchemaField(\"Conformidad\", \"STRING\"),\n",
        "        bigquery.SchemaField(\"Conformidad_Bin\", \"INTEGER\"),\n",
        "    ],\n",
        "    write_disposition=\"WRITE_APPEND\",  #Si desea agregar datos a la tabla existente\n",
        ")\n",
        "\n",
        "#Cargar DataFrame completo\n",
        "load_job = client.load_table_from_dataframe(df_cleaned, table_id, job_config=job_config)\n",
        "load_job.result()\n",
        "print(f\" Datos cargados en la tabla general: {table_id}\")"
      ],
      "metadata": {
        "id": "IAacfPt-kHJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Conversión de Datos y Carga a BigQuery"
      ],
      "metadata": {
        "id": "k9QWdusEwTqn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Verificar los tipos de datos después de la conversión\n",
        "print(\"Datos a importar en Google Cloud BigQuery:\")\n",
        "print(df_cleaned.dtypes)\n",
        "\n",
        "#Cargar el DataFrame en BigQuery\n",
        "tipos_vino = df_cleaned['Tipo_de_Vino'].unique()\n",
        "for tipo in tipos_vino:\n",
        "    df_vino = df_cleaned[df_cleaned['Tipo_de_Vino'] == tipo]\n",
        "    table_name = f\"Tabla_Vinos_{tipo.lower().replace(' ', '_')}\"\n",
        "    table_id = f\"{project_id}.{dataset_id}.{table_name}\"\n",
        "\n",
        "    try:\n",
        "    #Esperar a que el job termine\n",
        "      load_job = client.load_table_from_dataframe(df_vino, table_id, job_config=job_config)\n",
        "      load_job.result()\n",
        "      print(f\"Datos del tipo '{tipo}' cargados en: {table_id}\")\n",
        "\n",
        "    except Exception as e:\n",
        "      print(f\"Error al cargar datos del tipo '{tipo}': {e}\")"
      ],
      "metadata": {
        "id": "HrCEUM4-dKNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Validar la cuenta de Google Cloud a donde los datos han sido cargados\n",
        "creds, project = default()\n",
        "print(f\"El dataset ha sido subido al siguiente proyecto: {project}\")\n",
        "print(f\"Cuenta autenticada: {creds.service_account_email}\")"
      ],
      "metadata": {
        "id": "uDOoJ3zjyB56"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}