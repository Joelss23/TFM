# MODELO DE APRENDIZAJE AUTOMÁTICO PARA LA GESTIÓN DE CALIDAD Y PRODUCCION VINICOLA: IMPLEMENTACIÓN DE UN SISTEMA DE CALIDAD BASADO EN DATOS
## 1. Conexión a Synology Drive y Extracción de Datos
import os
import pandas as pd

# Conectar a Synology Drive (ajustar la ruta según tu configuración)
drive_path = "/ruta/a/tu/synology_drive"
archivo_datos = os.path.join(drive_path, "datos_vino.csv")

# Leer los datos
data = pd.read_csv(archivo_datos)

print("Datos cargados desde Synology Drive:")
print(data.head())
## 2. Apache Kafka para Gestionar el Flujo de Datos
from kafka import KafkaProducer, KafkaConsumer
import json

# Conexión al servidor de Kafka
producer = KafkaProducer(bootstrap_servers='localhost:9092', value_serializer=lambda x: json.dumps(x).encode('utf-8'))
consumer = KafkaConsumer('vino-topic', bootstrap_servers='localhost:9092', value_deserializer=lambda x: json.loads(x.decode('utf-8')))

# Enviar un mensaje a Kafka (por ejemplo, el dataframe)
def enviar_datos_kafka(df):
    for _, row in df.iterrows():
        message = row.to_dict()
        producer.send('vino-topic', value=message)
## 3. Consumidor de Kafka (leer y predecir datos)
def consumir_y_predecir():
    for mensaje in consumer:
        datos_vino = mensaje.value
        # Predecir calidad con el modelo (esto se completará más tarde)
        calidad_predicha = predecir_calidad(datos_vino)
        print(f"Vino predicho como: {'Buena calidad' if calidad_predicha == 1 else 'Baja calidad'}")

# Función para predecir calidad (temporal, se desarrollará más adelante)
def predecir_calidad(datos_vino):
    # Este código se completará más tarde con el modelo de TensorFlow
    return 1  # Ejemplo de predicción de vino de buena calidad
## 4. Análisis Exploratorio
# Verificar valores faltantes
print("\nValores faltantes:")
print(data.isnull().sum())

# Eliminar filas duplicadas
data = data.drop_duplicates()

# Estadísticas descriptivas de las variables
print("\nEstadísticas descriptivas de las variables:")
print(data.describe())

# Identificar valores desconocidos
for column in data.columns:
    print(f"\nValores únicos en {column}:")
    print(data[column].unique())
## 5. Ingeniería de Variables
# Crear una variable "Conformidad" basada en los parámetros establecidos para cada tipo de vino

def check_conformity(row):
    # Parámetros para el vino Tinto
    if row['type'] == 'Vinotinto':
        if (12.5 <= row['alcohol'] <= 14.5 and
            20 <= row['free_sulfur'] <= 30 and
            row['total_sulfur'] <= 150 and
            4.5 <= row['total_acidity'] <= 6.0 and
            row['volatile_acidity'] <= 0.6 and
            3.3 <= row['ph'] <= 3.6 and
            row['reducing_sugars'] < 4 and
            4.0 <= row['fixed_acidity'] <= 6.5):
            return 1  # Buen vino
        else:
            return 0  # Vino de baja calidad

    # Parámetros para el vino Blanco
    elif row['type'] == 'Blanco':
        if (11.5 <= row['alcohol'] <= 13.5 and
            25 <= row['free_sulfur'] <= 40 and
            row['total_sulfur'] <= 180 and
            5.5 <= row['total_acidity'] <= 7.5 and
            row['volatile_acidity'] <= 0.5 and
            3.1 <= row['ph'] <= 3.4 and
            row['reducing_sugars'] < 4 and
            4.5 <= row['fixed_acidity'] <= 7.0):
            return 1  # Buen vino
        else:
            return 0  # Vino de baja calidad

    # Parámetros para el vino Rosado
    elif row['type'] == 'Rosado':
        if (11.5 <= row['alcohol'] <= 13.5 and
            25 <= row['free_sulfur'] <= 40 and
            row['total_sulfur'] <= 180 and
            5.0 <= row['total_acidity'] <= 7.0 and
            row['volatile_acidity'] <= 0.5 and
            3.1 <= row['ph'] <= 3.5 and
            row['reducing_sugars'] < 4 and
            4.5 <= row['fixed_acidity'] <= 6.5):
            return 1  # Buen vino
        else:
            return 0  # Vino de baja calidad

    return 0  # Si no coincide con ningún tipo de vino

# Aplicar la función para generar la columna 'Conformidad'
data['Conformidad'] = data.apply(check_conformity, axis=1)

# Verificar que la variable fue creada correctamente
print("\nMuestra de datos con la variable 'Conformidad':")
print(data[['type', 'alcohol', 'free_sulfur', 'total_sulfur', 'total_acidity', 'volatile_acidity', 'ph', 'reducing_sugars', 'fixed_acidity', 'Conformidad']].head())
## 6. Eliminar Variables No Numéricas
# Eliminar columnas no numéricas (ejemplo: tipo de vino, que es categórica)
data = data.select_dtypes(include=['number'])
## 7. Eliminar Variables No Relevantes
# Eliminar columnas que no son relevantes para el modelo (ajustar según tu análisis)
data = data.drop(columns=['id', 'name'], errors='ignore')
## 8. Análisis por Tipo de Vino
# Realizar análisis diferente para cada tipo de vino
for tipo in data['type'].unique():
    print(f"\nAnálisis para {tipo}:")
    vino_tipo = data[data['type'] == tipo]
    print(vino_tipo.describe())
## 9. Modelo de TensorFlow para Predecir la Calidad del Vino
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

# Dividir el dataset en variables predictoras (X) y variable objetivo (y)
X = data.drop(columns=['Conformidad', 'type'])  # Eliminar 'type' y 'Conformidad'
y = data['Conformidad']

# Normalizar los datos
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Dividir los datos en entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# Construir el modelo de red neuronal
model = Sequential([
    Dense(64, activation='relu', input_dim=X_train.shape[1]),
    Dense(32, activation='relu'),
    Dense(1, activation='sigmoid')
])

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Entrenar el modelo
model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)

# Evaluar el modelo
loss, accuracy = model.evaluate(X_test, y_test)
print(f"\nPrecisión del modelo: {accuracy*100:.2f}%")

## 10. Comparar Diferentes Modelos
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC

# Crear y evaluar el modelo de Random Forest
rf_model = RandomForestClassifier(random_state=42)
rf_model.fit(X_train, y_train)
rf_pred = rf_model.predict(X_test)
rf_accuracy = accuracy_score(y_test, rf_pred)

# Crear y evaluar el modelo de Regresión Logística
lr_model = LogisticRegression(random_state=42)
lr_model.fit(X_train, y_train)
lr_pred = lr_model.predict(X_test)
lr_accuracy = accuracy_score(y_test, lr_pred)

# Crear y evaluar el modelo de SVM
svm_model = SVC(random_state=42)
svm_model.fit(X_train, y_train)
svm_pred = svm_model.predict(X_test)
svm_accuracy = accuracy_score(y_test, svm_pred)

# Mostrar resultados comparativos
print("\nComparación de modelos:")
print(f"Red Neuronal: {accuracy*100:.2f}%")
print(f"Random Forest: {rf_accuracy*100:.2f}%")
print(f"Regresión Logística: {lr_accuracy*100:.2f}%")
print(f"SVM: {svm_accuracy*100:.2f}%")
## 11. Análisis de Sensibilidad y Interpretabilidad
# Usar un modelo de Random Forest para obtener la importancia de las características
importances = rf_model.feature_importances_
print("\nImportancia de las características (Random Forest):")
for feature, importance in zip(X.columns, importances):
    print(f"{feature}: {importance:.4f}")
## 12. Métodos de Evaluación Adicionales
# Métricas adicionales de evaluación para la red neuronal
y_pred = model.predict(X_test)
y_pred = (y_pred > 0.5).astype(int)  # Convertir a 0 o 1

print("\nMétricas de Evaluación (Red Neuronal):")
print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))
## 13. Balance de Clases
from imblearn.over_sampling import SMOTE

# Balancear las clases utilizando SMOTE (Synthetic Minority Over-sampling Technique)
smote = SMOTE(random_state=42)
X_res, y_res = smote.fit_resample(X_train, y_train)

# Volver a entrenar el modelo con los datos balanceados
model.fit(X_res, y_res, epochs=10, batch_size=32, validation_split=0.2)
## 14. Validación Cruzada
from sklearn.model_selection import cross_val_score

# Validación cruzada para el modelo de red neuronal
cv_scores = cross_val_score(model, X_scaled, y, cv=5, scoring='accuracy')
print(f"\nPuntajes de validación cruzada: {cv_scores}")
print(f"Puntaje promedio de validación cruzada: {cv_scores.mean():.4f}")
## 15. Análisis de Outliers (Valores atípicos)
import seaborn as sns
import matplotlib.pyplot as plt

# Boxplots para detectar outliers
plt.figure(figsize=(10, 6))
sns.boxplot(data=data)
plt.title("Análisis de Outliers")
plt.show()

# Eliminar los outliers usando el rango intercuartílico (IQR)
Q1 = data.quantile(0.25)
Q3 = data.quantile(0.75)
IQR = Q3 - Q1

data_clean = data[~((data < (Q1 - 1.5 * IQR)) | (data > (Q3 + 1.5 * IQR))).any(axis=1)]
## 16. Escribir Predicciones en Archivo CSV
# Hacer predicciones con el modelo entrenado
predicciones = model.predict(X_test)
predicciones = (predicciones > 0.5).astype(int)  # Convertir a 0 o 1

# Guardar las predicciones en un archivo CSV
predicciones_df = pd.DataFrame(predicciones, columns=['Predicción'])
predicciones_df.to_csv('predicciones_vino.csv', index=False)
## 17. Actualizar el Consumidor de Kafka para Guardar las Predicciones
# Actualizar el consumidor para incluir predicciones en Kafka
def consumir_y_guardar_predicciones():
    for mensaje in consumer:
        datos_vino = mensaje.value
        calidad_predicha = predecir_calidad(datos_vino)
        datos_vino['predicción'] = calidad_predicha
        # Enviar la predicción de vuelta a Kafka (se podría usar otro topic para predicciones)
        producer.send('vino-predicciones-topic', value=datos_vino)

# Llamar a la función de consumidor para realizar la predicción
consumir_y_guardar_predicciones()
# Conectar las predicciones con PBI para realizar las predicciones
